{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "ttention mechanism and Seq2seq model.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_lyizjfl",
        "jupyter": {},
        "tags": [],
        "id": "2D4703A032B741F68676C00CF5B06CAF",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch \n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "graffitiCellId": "id_ucnczrs",
        "scrolled": false,
        "jupyter": {},
        "tags": [],
        "id": "60B68D50106A4FBD9CA3C2B863146405",
        "colab_type": "code",
        "colab": {},
        "outputId": "2943f133-b050-4462-d362-b6e3652abbea"
      },
      "source": [
        "import os\n",
        "def file_name_walk(file_dir):\n",
        "    for root, dirs, files in os.walk(file_dir):\n",
        "#         print(\"root\", root)  # 当前目录路径\n",
        "         print(\"dirs\", dirs)  # 当前路径下所有子目录\n",
        "         print(\"files\", files)  # 当前路径下所有非目录子文件\n",
        "\n",
        "file_name_walk(\"/home/kesci/input/fraeng6506\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dirs []\n",
            "files ['_about.txt', 'fra.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_39i6msf",
        "jupyter": {},
        "tags": [],
        "id": "CD9DB3F8099F49FB886E0B5029173F44",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SequenceMask(X, X_len,value=-1e6):\n",
        "    maxlen = X.size(1)\n",
        "    #print(X.size(),torch.arange((maxlen),dtype=torch.float)[None, :],'\\n',X_len[:, None] )\n",
        "    mask = torch.arange((maxlen),dtype=torch.float)[None, :] >= X_len[:, None]   \n",
        "    #print(mask)\n",
        "    X[mask]=value\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_mlvtr3b",
        "jupyter": {},
        "tags": [],
        "id": "B0BE96AC54A940878423D3C201ED8477",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def masked_softmax(X, valid_length):\n",
        "    # X: 3-D tensor, valid_length: 1-D or 2-D tensor\n",
        "    softmax = nn.Softmax(dim=-1)\n",
        "    if valid_length is None:\n",
        "        return softmax(X)\n",
        "    else:\n",
        "        shape = X.shape\n",
        "        if valid_length.dim() == 1:\n",
        "            try:\n",
        "                valid_length = torch.FloatTensor(valid_length.numpy().repeat(shape[1], axis=0))#[2,2,3,3]\n",
        "            except:\n",
        "                valid_length = torch.FloatTensor(valid_length.cpu().numpy().repeat(shape[1], axis=0))#[2,2,3,3]\n",
        "        else:\n",
        "            valid_length = valid_length.reshape((-1,))\n",
        "        # fill masked elements with a large negative, whose exp is 0\n",
        "        X = SequenceMask(X.reshape((-1, shape[-1])), valid_length)\n",
        " \n",
        "        return softmax(X).reshape(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_gjfsirw",
        "jupyter": {},
        "tags": [],
        "id": "2DC35416E322461FB2B9FDD6E0379A02",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "b01b32df-cd2e-4fc1-f527-669229c4398e"
      },
      "source": [
        "masked_softmax(torch.rand((2,2,4),dtype=torch.float), torch.FloatTensor([2,3]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5423, 0.4577, 0.0000, 0.0000],\n",
              "         [0.5290, 0.4710, 0.0000, 0.0000]],\n",
              "\n",
              "        [[0.2969, 0.2966, 0.4065, 0.0000],\n",
              "         [0.3607, 0.2203, 0.4190, 0.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_c01uiu4",
        "jupyter": {},
        "tags": [],
        "id": "55C627C9AD274B3AA4366F554A7A33C8",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "4296c4a5-98d2-40f6-b0a3-a043358fd399"
      },
      "source": [
        "torch.bmm(torch.ones((2,1,3), dtype = torch.float), torch.ones((2,3,2), dtype = torch.float))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[3., 3.]],\n",
              "\n",
              "        [[3., 3.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_qpr6dwm",
        "jupyter": {},
        "tags": [],
        "id": "3CB825EFC83C4F7892F0ED1D4038FB49",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save to the d2l package.\n",
        "class DotProductAttention(nn.Module): \n",
        "    def __init__(self, dropout, **kwargs):\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # query: (batch_size, #queries, d)\n",
        "    # key: (batch_size, #kv_pairs, d)\n",
        "    # value: (batch_size, #kv_pairs, dim_v)\n",
        "    # valid_length: either (batch_size, ) or (batch_size, xx)\n",
        "    def forward(self, query, key, value, valid_length=None):\n",
        "        d = query.shape[-1]\n",
        "        # set transpose_b=True to swap the last two dimensions of key\n",
        "        \n",
        "        scores = torch.bmm(query, key.transpose(1,2)) / math.sqrt(d)\n",
        "        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n",
        "        print(\"attention_weight\\n\",attention_weights)\n",
        "        return torch.bmm(attention_weights, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "graffitiCellId": "id_sy1n984",
        "jupyter": {},
        "tags": [],
        "id": "CD3484D8F62449C08842C768228EA444",
        "mdEditEnable": false,
        "colab_type": "text"
      },
      "source": [
        "### 测试\n",
        "现在我们创建了两个批，每个批有一个query和10个key-values对。我们通过valid_length指定，对于第一批，我们只关注前2个键-值对，而对于第二批，我们将检查前6个键-值对。因此，尽管这两个批处理具有相同的查询和键值对，但我们获得的输出是不同的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_rt2wg6w",
        "jupyter": {},
        "tags": [],
        "id": "DF454887CCD745858E6505AF13119489",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "59e431db-61aa-4e68-cc62-1d77eb2ff43f"
      },
      "source": [
        "atten = DotProductAttention(dropout=0)\n",
        "\n",
        "keys = torch.ones((2,10,2),dtype=torch.float)\n",
        "values = torch.arange((40), dtype=torch.float).view(1,10,4).repeat(2,1,1)\n",
        "atten(torch.ones((2,1,2),dtype=torch.float), keys, values, torch.FloatTensor([2, 6]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_weight\n",
            " tensor([[[0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000]],\n",
            "\n",
            "        [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
              "\n",
              "        [[10.0000, 11.0000, 12.0000, 13.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_2pmvrcv",
        "jupyter": {},
        "tags": [],
        "id": "047BD3F3C6DF46AC8C0FBAFF61F34B75",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save to the d2l package.\n",
        "class MLPAttention(nn.Module):  \n",
        "    def __init__(self, units,ipt_dim,dropout, **kwargs):\n",
        "        super(MLPAttention, self).__init__(**kwargs)\n",
        "        # Use flatten=True to keep query's and key's 3-D shapes.\n",
        "        self.W_k = nn.Linear(ipt_dim, units, bias=False)\n",
        "        self.W_q = nn.Linear(ipt_dim, units, bias=False)\n",
        "        self.v = nn.Linear(units, 1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, valid_length):\n",
        "        query, key = self.W_k(query), self.W_q(key)\n",
        "        #print(\"size\",query.size(),key.size())\n",
        "        # expand query to (batch_size, #querys, 1, units), and key to\n",
        "        # (batch_size, 1, #kv_pairs, units). Then plus them with broadcast.\n",
        "        features = query.unsqueeze(2) + key.unsqueeze(1)\n",
        "        #print(\"features:\",features.size())  #--------------开启\n",
        "        scores = self.v(features).squeeze(-1) \n",
        "        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n",
        "        return torch.bmm(attention_weights, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "graffitiCellId": "id_o2cxg9q",
        "jupyter": {},
        "tags": [],
        "id": "40A0160DE63247F881553CC224705D7A",
        "mdEditEnable": false,
        "colab_type": "text"
      },
      "source": [
        "### 测试\n",
        "尽管MLPAttention包含一个额外的MLP模型，但如果给定相同的输入和相同的键，我们将获得与DotProductAttention相同的输出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_ji2koe2",
        "jupyter": {},
        "tags": [],
        "id": "A399CB39F56241048E63FFD6FD3E3AE9",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "7ae1d9f1-82bb-41d5-bb1c-dcb63766d37e"
      },
      "source": [
        "atten = MLPAttention(ipt_dim=2,units = 8, dropout=0)\n",
        "atten(torch.ones((2,1,2), dtype = torch.float), keys, values, torch.FloatTensor([2, 6]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
              "\n",
              "        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=<BmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_xbbsd1x",
        "jupyter": {},
        "tags": [],
        "id": "5F439000597B4D638C3C6A85BA82A82D",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/home/kesci/input/d2len9900')\n",
        "import d2l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_n3xn2jo",
        "jupyter": {},
        "tags": [],
        "id": "421CF4D81A7E43378AF5C53236DC0586",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqAttentionDecoder(d2l.Decoder):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0, **kwargs):\n",
        "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
        "        self.attention_cell = MLPAttention(num_hiddens,num_hiddens, dropout)\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.LSTM(embed_size+ num_hiddens,num_hiddens, num_layers, dropout=dropout)\n",
        "        self.dense = nn.Linear(num_hiddens,vocab_size)\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_valid_len, *args):\n",
        "        outputs, hidden_state = enc_outputs\n",
        "#         print(\"first:\",outputs.size(),hidden_state[0].size(),hidden_state[1].size())\n",
        "        # Transpose outputs to (batch_size, seq_len, hidden_size)\n",
        "        return (outputs.permute(1,0,-1), hidden_state, enc_valid_len)\n",
        "        #outputs.swapaxes(0, 1)\n",
        "        \n",
        "    def forward(self, X, state):\n",
        "        enc_outputs, hidden_state, enc_valid_len = state\n",
        "        #(\"X.size\",X.size())\n",
        "        X = self.embedding(X).transpose(0,1)\n",
        "#         print(\"Xembeding.size2\",X.size())\n",
        "        outputs = []\n",
        "        for l, x in enumerate(X):\n",
        "#             print(f\"\\n{l}-th token\")\n",
        "#             print(\"x.first.size()\",x.size())\n",
        "            # query shape: (batch_size, 1, hidden_size)\n",
        "            # select hidden state of the last rnn layer as query\n",
        "            query = hidden_state[0][-1].unsqueeze(1) # np.expand_dims(hidden_state[0][-1], axis=1)\n",
        "            # context has same shape as query\n",
        "#             print(\"query enc_outputs, enc_outputs:\\n\",query.size(), enc_outputs.size(), enc_outputs.size())\n",
        "            context = self.attention_cell(query, enc_outputs, enc_outputs, enc_valid_len)\n",
        "            # Concatenate on the feature dimension\n",
        "#             print(\"context.size:\",context.size())\n",
        "            x = torch.cat((context, x.unsqueeze(1)), dim=-1)\n",
        "            # Reshape x to (1, batch_size, embed_size+hidden_size)\n",
        "#             print(\"rnn\",x.size(), len(hidden_state))\n",
        "            out, hidden_state = self.rnn(x.transpose(0,1), hidden_state)\n",
        "            outputs.append(out)\n",
        "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
        "        return outputs.transpose(0, 1), [enc_outputs, hidden_state,\n",
        "                                        enc_valid_len]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_5u9j8bu",
        "jupyter": {},
        "tags": [],
        "id": "4CCF2FAC8DE741D2B86E509FFA6F33DB",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "90fd3823-98b5-43dd-b917-d5bee9c187d3"
      },
      "source": [
        "encoder = d2l.Seq2SeqEncoder(vocab_size=10, embed_size=8,\n",
        "                            num_hiddens=16, num_layers=2)\n",
        "# encoder.initialize()\n",
        "decoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8,\n",
        "                                  num_hiddens=16, num_layers=2)\n",
        "X = torch.zeros((4, 7),dtype=torch.long)\n",
        "print(\"batch size=4\\nseq_length=7\\nhidden dim=16\\nnum_layers=2\\n\")\n",
        "print('encoder output size:', encoder(X)[0].size())\n",
        "print('encoder hidden size:', encoder(X)[1][0].size())\n",
        "print('encoder memory size:', encoder(X)[1][1].size())\n",
        "state = decoder.init_state(encoder(X), None)\n",
        "out, state = decoder(X, state)\n",
        "out.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch size=4\n",
            "seq_length=7\n",
            "hidden dim=16\n",
            "num_layers=2\n",
            "\n",
            "encoder output size: torch.Size([7, 4, 16])\n",
            "encoder hidden size: torch.Size([2, 4, 16])\n",
            "encoder memory size: torch.Size([2, 4, 16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([2, 4, 16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_3uv6guo",
        "jupyter": {},
        "tags": [],
        "id": "6DC0F075B2EA4EA78B6D405A35D896CC",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import torch\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torch.utils import data\n",
        "import sys\n",
        "import collections\n",
        "\n",
        "class Vocab(object): # This class is saved in d2l.\n",
        "  def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n",
        "    # sort by frequency and token\n",
        "    counter = collections.Counter(tokens)\n",
        "    token_freqs = sorted(counter.items(), key=lambda x: x[0])\n",
        "    token_freqs.sort(key=lambda x: x[1], reverse=True)\n",
        "    if use_special_tokens:\n",
        "      # padding, begin of sentence, end of sentence, unknown\n",
        "      self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)\n",
        "      tokens = ['', '', '', '']\n",
        "    else:\n",
        "      self.unk = 0\n",
        "      tokens = ['']\n",
        "    tokens += [token for token, freq in token_freqs if freq >= min_freq]\n",
        "    self.idx_to_token = []\n",
        "    self.token_to_idx = dict()\n",
        "    for token in tokens:\n",
        "      self.idx_to_token.append(token)\n",
        "      self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.idx_to_token)\n",
        "  \n",
        "  def __getitem__(self, tokens):\n",
        "    if not isinstance(tokens, (list, tuple)):\n",
        "      return self.token_to_idx.get(tokens, self.unk)\n",
        "    else:\n",
        "      return [self.__getitem__(token) for token in tokens]\n",
        "    \n",
        "  def to_tokens(self, indices):\n",
        "    if not isinstance(indices, (list, tuple)):\n",
        "      return self.idx_to_token[indices]\n",
        "    else:\n",
        "      return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "def load_data_nmt(batch_size, max_len, num_examples=1000):\n",
        "    \"\"\"Download an NMT dataset, return its vocabulary and data iterator.\"\"\"\n",
        "    # Download and preprocess\n",
        "    def preprocess_raw(text):\n",
        "        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
        "        out = ''\n",
        "        for i, char in enumerate(text.lower()):\n",
        "            if char in (',', '!', '.') and text[i-1] != ' ':\n",
        "                out += ' '\n",
        "            out += char\n",
        "        return out \n",
        "\n",
        "\n",
        "    with open('/home/kesci/input/fraeng6506/fra.txt', 'r') as f:\n",
        "      raw_text = f.read()\n",
        "\n",
        "\n",
        "    text = preprocess_raw(raw_text)\n",
        "\n",
        "    # Tokenize\n",
        "    source, target = [], []\n",
        "    for i, line in enumerate(text.split('\\n')):\n",
        "        if i >= num_examples:\n",
        "            break\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) >= 2:\n",
        "            source.append(parts[0].split(' '))\n",
        "            target.append(parts[1].split(' '))\n",
        "\n",
        "    # Build vocab\n",
        "    def build_vocab(tokens):\n",
        "        tokens = [token for line in tokens for token in line]\n",
        "        return Vocab(tokens, min_freq=3, use_special_tokens=True)\n",
        "    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n",
        "\n",
        "    # Convert to index arrays\n",
        "    def pad(line, max_len, padding_token):\n",
        "        if len(line) > max_len:\n",
        "            return line[:max_len]\n",
        "        return line + [padding_token] * (max_len - len(line))\n",
        "\n",
        "    def build_array(lines, vocab, max_len, is_source):\n",
        "        lines = [vocab[line] for line in lines]\n",
        "        if not is_source:\n",
        "            lines = [[vocab.bos] + line + [vocab.eos] for line in lines]\n",
        "        array = torch.tensor([pad(line, max_len, vocab.pad) for line in lines])\n",
        "        valid_len = (array != vocab.pad).sum(1)\n",
        "        return array, valid_len\n",
        "\n",
        "    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n",
        "    src_array, src_valid_len = build_array(source, src_vocab, max_len, True)\n",
        "    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, max_len, False)\n",
        "    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
        "    train_iter = data.DataLoader(train_data, batch_size, shuffle=True)\n",
        "    return src_vocab, tgt_vocab, train_iter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_uwt29qm",
        "jupyter": {},
        "tags": [],
        "id": "16B6DBF49DE6462CB969E7FEB2B80EA4",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
        "batch_size, num_steps = 64, 10\n",
        "lr, num_epochs, ctx = 0.005, 500, d2l.try_gpu()\n",
        "\n",
        "src_vocab, tgt_vocab, train_iter = load_data_nmt(batch_size, num_steps)\n",
        "encoder = d2l.Seq2SeqEncoder(\n",
        "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "decoder = Seq2SeqAttentionDecoder(\n",
        "    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "model = d2l.EncoderDecoder(encoder, decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_l50r9v2",
        "scrolled": false,
        "jupyter": {},
        "tags": [],
        "id": "C85DB18574124B778FF37F0C939A87CF",
        "colab_type": "code",
        "colab": {},
        "outputId": "9a50455f-6368-4fbb-d728-8c771bd7ada7"
      },
      "source": [
        "d2l.train_s2s_ch9(model, train_iter, lr, num_epochs, ctx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch   50,loss 0.104, time 54.7 sec\n",
            "epoch  100,loss 0.046, time 54.8 sec\n",
            "epoch  150,loss 0.031, time 54.7 sec\n",
            "epoch  200,loss 0.027, time 54.3 sec\n",
            "epoch  250,loss 0.025, time 54.3 sec\n",
            "epoch  300,loss 0.024, time 54.4 sec\n",
            "epoch  350,loss 0.024, time 54.4 sec\n",
            "epoch  400,loss 0.024, time 54.5 sec\n",
            "epoch  450,loss 0.023, time 54.4 sec\n",
            "epoch  500,loss 0.023, time 54.7 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_fgsubff",
        "jupyter": {},
        "tags": [],
        "id": "59CD0BDF632440938BF388ACCD017A09",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "65df7f79-a65e-4931-85fe-5acf287b7d13"
      },
      "source": [
        "for sentence in ['Go .', 'Good Night !', \"I'm OK .\", 'I won !']:\n",
        "    print(sentence + ' => ' + d2l.predict_s2s_ch9(\n",
        "        model, sentence, src_vocab, tgt_vocab, num_steps, ctx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go . => va !\n",
            "Good Night ! =>   !\n",
            "I'm OK . => ça va .\n",
            "I won ! => j'ai gagné !\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}