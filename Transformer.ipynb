{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_lyizjfl",
        "jupyter": {},
        "tags": [],
        "id": "27895557063B415E88AE1B50D61591EE",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "sys.path.append('/home/kesci/input/d2len9900')\n",
        "import d2l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_qrh3n7g",
        "jupyter": {},
        "tags": [],
        "id": "FC8FDB3160A948EA87012C0479714887",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SequenceMask(X, X_len,value=-1e6):\n",
        "    maxlen = X.size(1)\n",
        "    X_len = X_len.to(X.device)\n",
        "    #print(X.size(),torch.arange((maxlen),dtype=torch.float)[None, :],'\\n',X_len[:, None] )\n",
        "    mask = torch.arange((maxlen), dtype=torch.float, device=X.device)\n",
        "    mask = mask[None, :] < X_len[:, None]\n",
        "    #print(mask)\n",
        "    X[~mask]=value\n",
        "    return X\n",
        "\n",
        "def masked_softmax(X, valid_length):\n",
        "    # X: 3-D tensor, valid_length: 1-D or 2-D tensor\n",
        "    softmax = nn.Softmax(dim=-1)\n",
        "    if valid_length is None:\n",
        "        return softmax(X)\n",
        "    else:\n",
        "        shape = X.shape\n",
        "        if valid_length.dim() == 1:\n",
        "            try:\n",
        "                valid_length = torch.FloatTensor(valid_length.numpy().repeat(shape[1], axis=0))#[2,2,3,3]\n",
        "            except:\n",
        "                valid_length = torch.FloatTensor(valid_length.cpu().numpy().repeat(shape[1], axis=0))#[2,2,3,3]\n",
        "        else:\n",
        "            valid_length = valid_length.reshape((-1,))\n",
        "        # fill masked elements with a large negative, whose exp is 0\n",
        "        X = SequenceMask(X.reshape((-1, shape[-1])), valid_length)\n",
        " \n",
        "        return softmax(X).reshape(shape)\n",
        "\n",
        "# Save to the d2l package.\n",
        "class DotProductAttention(nn.Module): \n",
        "    def __init__(self, dropout, **kwargs):\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # query: (batch_size, #queries, d)\n",
        "    # key: (batch_size, #kv_pairs, d)\n",
        "    # value: (batch_size, #kv_pairs, dim_v)\n",
        "    # valid_length: either (batch_size, ) or (batch_size, xx)\n",
        "    def forward(self, query, key, value, valid_length=None):\n",
        "        d = query.shape[-1]\n",
        "        # set transpose_b=True to swap the last two dimensions of key\n",
        "        scores = torch.bmm(query, key.transpose(1,2)) / math.sqrt(d)\n",
        "        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n",
        "        return torch.bmm(attention_weights, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_39i6msf",
        "jupyter": {},
        "tags": [],
        "id": "77DA0FFB2D2E4A7C83FBCEEE64D69DE4",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_heads, dropout, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = DotProductAttention(dropout)\n",
        "        self.W_q = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        self.W_k = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        self.W_v = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        self.W_o = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "    \n",
        "    def forward(self, query, key, value, valid_length):\n",
        "        # query, key, and value shape: (batch_size, seq_len, dim),\n",
        "        # where seq_len is the length of input sequence\n",
        "        # valid_length shape is either (batch_size, )\n",
        "        # or (batch_size, seq_len).\n",
        "\n",
        "        # Project and transpose query, key, and value from\n",
        "        # (batch_size, seq_len, hidden_size * num_heads) to\n",
        "        # (batch_size * num_heads, seq_len, hidden_size).\n",
        "        \n",
        "        query = transpose_qkv(self.W_q(query), self.num_heads)\n",
        "        key = transpose_qkv(self.W_k(key), self.num_heads)\n",
        "        value = transpose_qkv(self.W_v(value), self.num_heads)\n",
        "        \n",
        "        if valid_length is not None:\n",
        "            # Copy valid_length by num_heads times\n",
        "            device = valid_length.device\n",
        "            valid_length = valid_length.cpu().numpy() if valid_length.is_cuda else valid_length.numpy()\n",
        "            if valid_length.ndim == 1:\n",
        "                valid_length = torch.FloatTensor(np.tile(valid_length, self.num_heads))\n",
        "            else:\n",
        "                valid_length = torch.FloatTensor(np.tile(valid_length, (self.num_heads,1)))\n",
        "\n",
        "            valid_length = valid_length.to(device)\n",
        "            \n",
        "        output = self.attention(query, key, value, valid_length)\n",
        "        output_concat = transpose_output(output, self.num_heads)\n",
        "        return self.W_o(output_concat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_mlvtr3b",
        "jupyter": {},
        "tags": [],
        "id": "E5580A1C9FFB434094200A8CBF1F31F6",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transpose_qkv(X, num_heads):\n",
        "    # Original X shape: (batch_size, seq_len, hidden_size * num_heads),\n",
        "    # -1 means inferring its value, after first reshape, X shape:\n",
        "    # (batch_size, seq_len, num_heads, hidden_size)\n",
        "    X = X.view(X.shape[0], X.shape[1], num_heads, -1)\n",
        "    \n",
        "    # After transpose, X shape: (batch_size, num_heads, seq_len, hidden_size)\n",
        "    X = X.transpose(2, 1).contiguous()\n",
        "\n",
        "    # Merge the first two dimensions. Use reverse=True to infer shape from\n",
        "    # right to left.\n",
        "    # output shape: (batch_size * num_heads, seq_len, hidden_size)\n",
        "    output = X.view(-1, X.shape[2], X.shape[3])\n",
        "    return output\n",
        "\n",
        "\n",
        "# Saved in the d2l package for later use\n",
        "def transpose_output(X, num_heads):\n",
        "    # A reversed version of transpose_qkv\n",
        "    X = X.view(-1, num_heads, X.shape[1], X.shape[2])\n",
        "    X = X.transpose(2, 1).contiguous()\n",
        "    return X.view(X.shape[0], X.shape[1], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_gjfsirw",
        "scrolled": false,
        "jupyter": {},
        "tags": [],
        "id": "165195251F95481C87506682632ECAA0",
        "colab_type": "code",
        "colab": {},
        "outputId": "1867293f-b4a4-44d9-9be5-7282695a8d92"
      },
      "source": [
        "cell = MultiHeadAttention(5, 9, 3, 0.5)\n",
        "X = torch.ones((2, 4, 5))\n",
        "valid_length = torch.FloatTensor([2, 3])\n",
        "cell(X, X, X, valid_length).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_qpr6dwm",
        "jupyter": {},
        "tags": [],
        "id": "7D631C416175432C8E15C0949EEAADD8",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save to the d2l package.\n",
        "class PositionWiseFFN(nn.Module):\n",
        "    def __init__(self, input_size, ffn_hidden_size, hidden_size_out, **kwargs):\n",
        "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
        "        self.ffn_1 = nn.Linear(input_size, ffn_hidden_size)\n",
        "        self.ffn_2 = nn.Linear(ffn_hidden_size, hidden_size_out)\n",
        "        \n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.ffn_2(F.relu(self.ffn_1(X)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_rt2wg6w",
        "jupyter": {},
        "tags": [],
        "id": "342DB0217414477AA49EAE019D18A40B",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "22f89876-22c1-4e75-929e-8f0002b847b1"
      },
      "source": [
        "ffn = PositionWiseFFN(4, 4, 8)\n",
        "out = ffn(torch.ones((2,3,4)))\n",
        "\n",
        "print(out, out.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.2040, -0.1118, -0.1163,  0.1494,  0.3978, -0.5561,  0.4662,\n",
            "          -0.6598],\n",
            "         [ 0.2040, -0.1118, -0.1163,  0.1494,  0.3978, -0.5561,  0.4662,\n",
            "          -0.6598],\n",
            "         [ 0.2040, -0.1118, -0.1163,  0.1494,  0.3978, -0.5561,  0.4662,\n",
            "          -0.6598]],\n",
            "\n",
            "        [[ 0.2040, -0.1118, -0.1163,  0.1494,  0.3978, -0.5561,  0.4662,\n",
            "          -0.6598],\n",
            "         [ 0.2040, -0.1118, -0.1163,  0.1494,  0.3978, -0.5561,  0.4662,\n",
            "          -0.6598],\n",
            "         [ 0.2040, -0.1118, -0.1163,  0.1494,  0.3978, -0.5561,  0.4662,\n",
            "          -0.6598]]], grad_fn=<AddBackward0>) torch.Size([2, 3, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_5aer6fc",
        "jupyter": {},
        "tags": [],
        "id": "9EA6172929A949B0ADDF5D3C9AA4DD26",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "88f379aa-7b21-4a24-efb4-290055b5ad48"
      },
      "source": [
        "layernorm = nn.LayerNorm(normalized_shape=2, elementwise_affine=True)\n",
        "batchnorm = nn.BatchNorm1d(num_features=2, affine=True)\n",
        "X = torch.FloatTensor([[1,2], [3,4]])\n",
        "print('layer norm:', layernorm(X))\n",
        "print('batch norm:', batchnorm(X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer norm: tensor([[-1.0000,  1.0000],\n",
            "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward>)\n",
            "batch norm: tensor([[-1.0000, -1.0000],\n",
            "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_2pmvrcv",
        "jupyter": {},
        "tags": [],
        "id": "F613FA3D7F634598832BFA21F4BE23F4",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save to the d2l package.\n",
        "class AddNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, dropout, **kwargs):\n",
        "        super(AddNorm, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "    \n",
        "    def forward(self, X, Y):\n",
        "        return self.norm(self.dropout(Y) + X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_ji2koe2",
        "jupyter": {},
        "tags": [],
        "id": "1031B32CEFB344F28BA2505954195AD3",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "fbea7f82-a12a-4308-b4df-d0832451e260"
      },
      "source": [
        "add_norm = AddNorm(4, 0.5)\n",
        "add_norm(torch.ones((2,3,4)), torch.ones((2,3,4))).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_xbbsd1x",
        "jupyter": {},
        "tags": [],
        "id": "A3322BF25A5446FEA39FEDBB230A60FD",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embedding_size, dropout, max_len=1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.P = np.zeros((1, max_len, embedding_size))\n",
        "        X = np.arange(0, max_len).reshape(-1, 1) / np.power(\n",
        "            10000, np.arange(0, embedding_size, 2)/embedding_size)\n",
        "        self.P[:, :, 0::2] = np.sin(X)\n",
        "        self.P[:, :, 1::2] = np.cos(X)\n",
        "        self.P = torch.FloatTensor(self.P)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        if X.is_cuda and not self.P.is_cuda:\n",
        "            self.P = self.P.cuda()\n",
        "        X = X + self.P[:, :X.shape[1], :]\n",
        "        return self.dropout(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_kn0kaqb",
        "jupyter": {},
        "tags": [],
        "id": "CDB21A80016E43A284D08F0D93E562F4",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "2d8a652b-7b21-4b8a-8ff0-1a0da92f4109"
      },
      "source": [
        "import numpy as np\n",
        "pe = PositionalEncoding(20, 0)\n",
        "Y = pe(torch.zeros((1, 100, 20))).numpy()\n",
        "d2l.plot(np.arange(100), Y[0, :, 4:8].T, figsize=(6, 2.5),\n",
        "         legend=[\"dim %d\" % p for p in [4, 5, 6, 7]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x180 with 1 Axes>"
            ],
            "text/html": [
              "<img src=\"https://cdn.kesci.com/rt_upload/CDB21A80016E43A284D08F0D93E562F4/q5kpj0ompw.svg\">"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_x22v188",
        "jupyter": {},
        "tags": [],
        "id": "D783201E79D043439F3E7C10D0F5003C",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, embedding_size, ffn_hidden_size, num_heads,\n",
        "                 dropout, **kwargs):\n",
        "        super(EncoderBlock, self).__init__(**kwargs)\n",
        "        self.attention = MultiHeadAttention(embedding_size, embedding_size, num_heads, dropout)\n",
        "        self.addnorm_1 = AddNorm(embedding_size, dropout)\n",
        "        self.ffn = PositionWiseFFN(embedding_size, ffn_hidden_size, embedding_size)\n",
        "        self.addnorm_2 = AddNorm(embedding_size, dropout)\n",
        "\n",
        "    def forward(self, X, valid_length):\n",
        "        Y = self.addnorm_1(X, self.attention(X, X, X, valid_length))\n",
        "        return self.addnorm_2(Y, self.ffn(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_j3zhyr4",
        "jupyter": {},
        "tags": [],
        "id": "8071DC6CEC654D2A9061D83C13505F36",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "0e1d2106-6d74-4b21-9275-77cac0967d80"
      },
      "source": [
        "# batch_size = 2, seq_len = 100, embedding_size = 24\n",
        "# ffn_hidden_size = 48, num_head = 8, dropout = 0.5\n",
        "\n",
        "X = torch.ones((2, 100, 24))\n",
        "encoder_blk = EncoderBlock(24, 48, 8, 0.5)\n",
        "encoder_blk(X, valid_length).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_zbq9tjf",
        "jupyter": {},
        "tags": [],
        "id": "22138781EF594DAD80EB068E33A0B292",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformerEncoder(d2l.Encoder):\n",
        "    def __init__(self, vocab_size, embedding_size, ffn_hidden_size,\n",
        "                 num_heads, num_layers, dropout, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.pos_encoding = PositionalEncoding(embedding_size, dropout)\n",
        "        self.blks = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            self.blks.append(\n",
        "                EncoderBlock(embedding_size, ffn_hidden_size,\n",
        "                             num_heads, dropout))\n",
        "\n",
        "    def forward(self, X, valid_length, *args):\n",
        "        X = self.pos_encoding(self.embed(X) * math.sqrt(self.embedding_size))\n",
        "        for blk in self.blks:\n",
        "            X = blk(X, valid_length)\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_vx2hsaf",
        "jupyter": {},
        "tags": [],
        "id": "2D50EE7D0CC24C3C9562EBAA5C51FF08",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "000115a4-a415-4f8f-8562-9442ad5dbf94"
      },
      "source": [
        "# test encoder\n",
        "encoder = TransformerEncoder(200, 24, 48, 8, 2, 0.5)\n",
        "encoder(torch.ones((2, 100)).long(), valid_length).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_ao2mjn9",
        "jupyter": {},
        "tags": [],
        "id": "B5D8DE77B835470B8ABB16FD9093CBB2",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embedding_size, ffn_hidden_size, num_heads,dropout,i,**kwargs):\n",
        "        super(DecoderBlock, self).__init__(**kwargs)\n",
        "        self.i = i\n",
        "        self.attention_1 = MultiHeadAttention(embedding_size, embedding_size, num_heads, dropout)\n",
        "        self.addnorm_1 = AddNorm(embedding_size, dropout)\n",
        "        self.attention_2 = MultiHeadAttention(embedding_size, embedding_size, num_heads, dropout)\n",
        "        self.addnorm_2 = AddNorm(embedding_size, dropout)\n",
        "        self.ffn = PositionWiseFFN(embedding_size, ffn_hidden_size, embedding_size)\n",
        "        self.addnorm_3 = AddNorm(embedding_size, dropout)\n",
        "    \n",
        "    def forward(self, X, state):\n",
        "        enc_outputs, enc_valid_length = state[0], state[1]\n",
        "        \n",
        "        # state[2][self.i] stores all the previous t-1 query state of layer-i\n",
        "        # len(state[2]) = num_layers\n",
        "        \n",
        "        # If training:\n",
        "        #     state[2] is useless.\n",
        "        # If predicting:\n",
        "        #     In the t-th timestep:\n",
        "        #         state[2][self.i].shape = (batch_size, t-1, hidden_size)\n",
        "        # Demo:\n",
        "        # love dogs ! [EOS]\n",
        "        #  |    |   |   |\n",
        "        #   Transformer \n",
        "        #    Decoder\n",
        "        #  |   |   |   |\n",
        "        #  I love dogs !\n",
        "        \n",
        "        if state[2][self.i] is None:\n",
        "            key_values = X\n",
        "        else:\n",
        "            # shape of key_values = (batch_size, t, hidden_size)\n",
        "            key_values = torch.cat((state[2][self.i], X), dim=1) \n",
        "        state[2][self.i] = key_values\n",
        "        \n",
        "        if self.training:\n",
        "            batch_size, seq_len, _ = X.shape\n",
        "            # Shape: (batch_size, seq_len), the values in the j-th column are j+1\n",
        "            valid_length = torch.FloatTensor(np.tile(np.arange(1, seq_len+1), (batch_size, 1))) \n",
        "            valid_length = valid_length.to(X.device)\n",
        "        else:\n",
        "            valid_length = None\n",
        "\n",
        "        X2 = self.attention_1(X, key_values, key_values, valid_length)\n",
        "        Y = self.addnorm_1(X, X2)\n",
        "        Y2 = self.attention_2(Y, enc_outputs, enc_outputs, enc_valid_length)\n",
        "        Z = self.addnorm_2(Y, Y2)\n",
        "        return self.addnorm_3(Z, self.ffn(Z)), state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_5mxi0su",
        "jupyter": {},
        "tags": [],
        "id": "A9BA1A943DE64FDC8A51022121BBF25D",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "a36d093e-2c50-4c4a-f30e-5f8b0abdb7bf"
      },
      "source": [
        "decoder_blk = DecoderBlock(24, 48, 8, 0.5, 0)\n",
        "X = torch.ones((2, 100, 24))\n",
        "state = [encoder_blk(X, valid_length), valid_length, [None]]\n",
        "decoder_blk(X, state)[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_uwit5bq",
        "jupyter": {},
        "tags": [],
        "id": "A08D05D6E69648E2851DC6CD464241CB",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformerDecoder(d2l.Decoder):\n",
        "    def __init__(self, vocab_size, embedding_size, ffn_hidden_size,\n",
        "                 num_heads, num_layers, dropout, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.pos_encoding = PositionalEncoding(embedding_size, dropout)\n",
        "        self.blks = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            self.blks.append(\n",
        "                DecoderBlock(embedding_size, ffn_hidden_size, num_heads,\n",
        "                             dropout, i))\n",
        "        self.dense = nn.Linear(embedding_size, vocab_size)\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_valid_length, *args):\n",
        "        return [enc_outputs, enc_valid_length, [None]*self.num_layers]\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        X = self.pos_encoding(self.embed(X) * math.sqrt(self.embedding_size))\n",
        "        for blk in self.blks:\n",
        "            X, state = blk(X, state)\n",
        "        return self.dense(X), state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_vxoc9ly",
        "jupyter": {},
        "tags": [],
        "id": "335EEDE006B94516B87E8612B38F36C0",
        "scrolled": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import torch\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torch.utils import data\n",
        "import sys\n",
        "import collections\n",
        "\n",
        "class Vocab(object): # This class is saved in d2l.\n",
        "  def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n",
        "    # sort by frequency and token\n",
        "    counter = collections.Counter(tokens)\n",
        "    token_freqs = sorted(counter.items(), key=lambda x: x[0])\n",
        "    token_freqs.sort(key=lambda x: x[1], reverse=True)\n",
        "    if use_special_tokens:\n",
        "      # padding, begin of sentence, end of sentence, unknown\n",
        "      self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)\n",
        "      tokens = ['', '', '', '']\n",
        "    else:\n",
        "      self.unk = 0\n",
        "      tokens = ['']\n",
        "    tokens += [token for token, freq in token_freqs if freq >= min_freq]\n",
        "    self.idx_to_token = []\n",
        "    self.token_to_idx = dict()\n",
        "    for token in tokens:\n",
        "      self.idx_to_token.append(token)\n",
        "      self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.idx_to_token)\n",
        "  \n",
        "  def __getitem__(self, tokens):\n",
        "    if not isinstance(tokens, (list, tuple)):\n",
        "      return self.token_to_idx.get(tokens, self.unk)\n",
        "    else:\n",
        "      return [self.__getitem__(token) for token in tokens]\n",
        "    \n",
        "  def to_tokens(self, indices):\n",
        "    if not isinstance(indices, (list, tuple)):\n",
        "      return self.idx_to_token[indices]\n",
        "    else:\n",
        "      return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "def load_data_nmt(batch_size, max_len, num_examples=1000):\n",
        "    \"\"\"Download an NMT dataset, return its vocabulary and data iterator.\"\"\"\n",
        "    # Download and preprocess\n",
        "    def preprocess_raw(text):\n",
        "        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
        "        out = ''\n",
        "        for i, char in enumerate(text.lower()):\n",
        "            if char in (',', '!', '.') and text[i-1] != ' ':\n",
        "                out += ' '\n",
        "            out += char\n",
        "        return out \n",
        "\n",
        "\n",
        "    with open('/home/kesci/input/fraeng6506/fra.txt', 'r') as f:\n",
        "      raw_text = f.read()\n",
        "\n",
        "\n",
        "    text = preprocess_raw(raw_text)\n",
        "\n",
        "    # Tokenize\n",
        "    source, target = [], []\n",
        "    for i, line in enumerate(text.split('\\n')):\n",
        "        if i >= num_examples:\n",
        "            break\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) >= 2:\n",
        "            source.append(parts[0].split(' '))\n",
        "            target.append(parts[1].split(' '))\n",
        "\n",
        "    # Build vocab\n",
        "    def build_vocab(tokens):\n",
        "        tokens = [token for line in tokens for token in line]\n",
        "        return Vocab(tokens, min_freq=3, use_special_tokens=True)\n",
        "    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n",
        "\n",
        "    # Convert to index arrays\n",
        "    def pad(line, max_len, padding_token):\n",
        "        if len(line) > max_len:\n",
        "            return line[:max_len]\n",
        "        return line + [padding_token] * (max_len - len(line))\n",
        "\n",
        "    def build_array(lines, vocab, max_len, is_source):\n",
        "        lines = [vocab[line] for line in lines]\n",
        "        if not is_source:\n",
        "            lines = [[vocab.bos] + line + [vocab.eos] for line in lines]\n",
        "        array = torch.tensor([pad(line, max_len, vocab.pad) for line in lines])\n",
        "        valid_len = (array != vocab.pad).sum(1)\n",
        "        return array, valid_len\n",
        "\n",
        "    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n",
        "    src_array, src_valid_len = build_array(source, src_vocab, max_len, True)\n",
        "    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, max_len, False)\n",
        "    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
        "    train_iter = data.DataLoader(train_data, batch_size, shuffle=True)\n",
        "    return src_vocab, tgt_vocab, train_iter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_ejtd65n",
        "jupyter": {},
        "tags": [],
        "id": "CF24003818D24C8EB13D73526386F6DA",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "a60bda82-272a-47f4-d294-12617a172a0e"
      },
      "source": [
        "import os\n",
        "\n",
        "import d2l\n",
        "\n",
        "# 平台暂时不支持gpu，现在会自动使用cpu训练，gpu可以用了之后会使用gpu来训练\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "embed_size, embedding_size, num_layers, dropout = 32, 32, 2, 0.05\n",
        "batch_size, num_steps = 64, 10\n",
        "lr, num_epochs, ctx = 0.005, 250, d2l.try_gpu()\n",
        "print(ctx)\n",
        "num_hiddens, num_heads = 64, 4\n",
        "\n",
        "src_vocab, tgt_vocab, train_iter = load_data_nmt(batch_size, num_steps)\n",
        "\n",
        "encoder = TransformerEncoder(\n",
        "    len(src_vocab), embedding_size, num_hiddens, num_heads, num_layers,\n",
        "    dropout)\n",
        "decoder = TransformerDecoder(\n",
        "    len(src_vocab), embedding_size, num_hiddens, num_heads, num_layers,\n",
        "    dropout)\n",
        "model = d2l.EncoderDecoder(encoder, decoder)\n",
        "d2l.train_s2s_ch9(model, train_iter, lr, num_epochs, ctx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "epoch   50,loss 0.048, time 53.3 sec\n",
            "epoch  100,loss 0.040, time 53.4 sec\n",
            "epoch  150,loss 0.037, time 53.5 sec\n",
            "epoch  200,loss 0.036, time 53.6 sec\n",
            "epoch  250,loss 0.035, time 53.5 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "graffitiCellId": "id_j2p7osp",
        "jupyter": {},
        "tags": [],
        "id": "5499C9F770424B3D8EE5F8CBAC59731C",
        "scrolled": false,
        "colab_type": "code",
        "colab": {},
        "outputId": "dbb4f60a-b85d-4586-f0be-a3acf5c4a35d"
      },
      "source": [
        "model.eval()\n",
        "for sentence in ['Go .', 'Wow !', \"I'm OK .\", 'I won !']:\n",
        "    print(sentence + ' => ' + d2l.predict_s2s_ch9(\n",
        "        model, sentence, src_vocab, tgt_vocab, num_steps, ctx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go . =>  !\n",
            "Wow ! =>  !\n",
            "I'm OK . => ça va .\n",
            "I won ! => j'ai gagné !\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}